{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF USING GOOGLE COLABORATORY -> RUN FIRST!!!\n",
    "# OTHERWISE -> IGNORE ;-)\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n",
    "# <font color=\"#003660\">Lesson 9: Hands-On Training: Developing Summarization Models in Resource-Limited Settings</font>\n",
    "\n",
    "<center><br><img width=256 src=\"https://git.uni-paderborn.de/data.analytics.teaching/aml4ta-2020/-/raw/master/resources/dag.png\"/><br></center>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<div>\n",
    "    <font color=\"#085986\"><b>By the end of this lesson, you will be able to...</b><br><br>\n",
    "        ... build and run your own summarization pipeline;<br>\n",
    "        ... critically analyze the performance of a summarization model; and<br>\n",
    "        ... optimize resource usage.<br>\n",
    "    </font>\n",
    "</div>\n",
    "</center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task</h2>\n",
    "\n",
    "<p>In today's session, we will focus on building a text summarization model, with an emphasis on efficient resource utilization. This includes using all available tools for optimal preprocessing and batching of text data, ensuring that the input to our model is streamlined and manageable, especially in the context of varying document lengths and sizes. Additionally, we will explore the implementation of mixed-precision training, which allows us to leverage the benefits of both FP16 and FP32 data types to balance training speed and model accuracy.</p>\n",
    "\n",
    "<p>Given the limited GPU resources typically available in academic settings, this exercise aims to provide a realistic experience in training NLP models under computational constraints. You will learn to adjust batch sizes, manage document lengths, and choose an appropriate number of samples, all while ensuring the model runs smoothly on the available hardware. This practical approach not only bolsters your coding skills but also instills an understanding of crucial efficiency considerations in model training.</p>\n",
    "\n",
    "<p>Moreover, a significant part of today's session will be dedicated to the critical evaluation of the summarization model. We will delve into selecting the right metrics for assessing model performance, including accuracy, coherence, and relevance of the generated summaries. This evaluation process is crucial for understanding the real-world applicability of the model and for learning how to critically assess outputs, an essential skill for any machine learning practitioner.</p>\n",
    "\n",
    "<h2>Guidance</h2>\n",
    "\n",
    "<ul>\n",
    "  <li>Begin by comprehending the structure of the base model you are working with.</li>\n",
    "  <li>Identify and correctly utilize the specific tokens associated with the chosen model architecture.</li>\n",
    "  <li>For models that need or suggest it, incorporate prompts into your documents prior to the training process.</li>\n",
    "  <li>Assess the memory demands of the models and explore different batch sizes through experimentation.</li>\n",
    "  <li>Investigate the appropriate metric(s) for evaluation and thoroughly evaluate their significance.</li>\n",
    "  <li>If necessary, concentrate on documents that are similar in length or subject matter to enhance the performance and reliability of this smaller, proof-of-concept model.</li>\n",
    "</ul>\n",
    "\n",
    "<h2>Useful Links</h2>\n",
    "\n",
    "<ul>\n",
    "  <li><a href=\"https://huggingface.co/learn/nlp-course/chapter1/7?fw=pt\">Hugging Face | Sequence-to-Sequence Models</a></li>\n",
    "  <li><a href=\"https://huggingface.co/docs/transformers/tasks/summarization\">Hugging Face | Summarization</a></li>\n",
    "  <li><a href=\"https://huggingface.co/docs/transformers/main_classes/data_collator\">Hugging Face | Data Collator</a></li>\n",
    "  <li><a href=\"https://huggingface.co/docs/transformers/v4.35.2/en/main_classes/trainer#transformers.Trainer\">Hugging Face | Trainer</a></li>\n",
    "  <li><a href=\"https://huggingface.co/docs/transformers/training#train-a-tensorflow-model-with-keras\">Hugging Face | Train with PyTorch Trainer (<i>under Show Pytorch Content</i>)</a></li>\n",
    "  <li><a href=\"https://huggingface.co/docs/datasets/index\">Hugging Face | Datasets</a></li>\n",
    "  <ul>\n",
    "    <li><a href=\"https://huggingface.co/datasets/cnn_dailymail\">CNN / Dailymail</a></li>\n",
    "    <li><a href=\"https://huggingface.co/datasets/newsroom\">Newsroom</a></li>\n",
    "    <li><a href=\"https://huggingface.co/datasets/samsum\">SAMsum</a></li>\n",
    "    <li>...</li>\n",
    "  </ul>\n",
    "  <li><a href=\"https://paperswithcode.com/datasets?task=text-summarization\">Papers With Code (Meta) | Text Summarization Datasets</a></li>\n",
    "  <li><a href=\"https://metatext.io/datasets-list/summarization-task\">Metatext | Summarization Datasets</a></li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "# Continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have fun ;-)\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
