{"cells":[{"cell_type":"markdown","metadata":{"id":"LJrKCbjZsqpo"},"source":["# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"]},{"cell_type":"markdown","metadata":{"id":"V-DU0hkyVyPi"},"source":["# <font color=\"#003660\">Week 1: Introduction to Natural Language Processing</font>"]},{"cell_type":"markdown","metadata":{"id":"mhy42GjRV3ON"},"source":["# <font color=\"#003660\">Notebook 4: Multi-class Classification</font>\n","\n","<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n","\n","<p>\n","<center>\n","<div>\n","    <font color=\"#085986\"><b>By the end of this lesson, you will be able to...</b><br><br>\n","        ... transform raw text into a term-document matrix, <br>\n","        ... train a binary classifier on the term-document matrix, and <br> ... and compete in a Kaggle competition.\n","    </font>\n","</div>\n","</center>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"C6vVpwIFsqps"},"source":["# Import packages\n","\n","As always, we first need to load a number of required Python packages:\n","- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n","- `SQLAlchemy`, together with `pymysql`, allows to communicate with SQL databases.\n","- `getpass` provides function to safely enter passwords.\n","- `spacy` offers industrial-strength natural language processing.\n","- `sklearn` is the de-facto standard machine learning package in Python."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8398,"status":"ok","timestamp":1666274863835,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"5NpTS4Z2Vvzy","outputId":"42b7e8e5-c69f-49cd-dd40-30dc87cbee8c"},"outputs":[],"source":["# Install packages\n","!pip install pymysql"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMrhkr83sqpt"},"outputs":[],"source":["import pandas as pd\n","from sqlalchemy import create_engine, text\n","import getpass\n","import spacy\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import metrics\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"markdown","metadata":{"id":"jZd82t53sqpu"},"source":["# Load documents"]},{"cell_type":"markdown","metadata":{"id":"IsrCafxksqpv"},"source":["We load our data from a MySQL database. For security reasons, we don't store the database credentials here; please have a look at Panda to get them."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31867,"status":"ok","timestamp":1666274895694,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"vSIGfKcXsqpv","outputId":"94277676-2cca-44b7-c99c-e6ca35430318"},"outputs":[],"source":["# Get credentials\n","user = input(\"Username: \")\n","passwd = getpass.getpass(\"Password: \")\n","server = input(\"Server: \")\n","db = input(\"Database: \")\n","\n","# Create an engine instance (SQLAlchemy)\n","engine = create_engine(\"mysql+pymysql://{}:{}@{}/{}\".format(user, passwd ,server, db))\n","\n","# Define SQL query\n","sql_query = \"SELECT * FROM WineDataset\"\n","\n","# Query dataset (pandas)\n","corpus = pd.DataFrame(engine.connect().execute(text(sql_query)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QlZ90YoJDiYr"},"outputs":[],"source":["top_countries = [\"US\",\"France\",\"Italy\",\"Spain\",\"Portugal\",\"Chile\",\"Argentina\",\"Austria\",\"Australia\",\"Germany\"]\n","corpus = corpus[corpus[\"country\"].isin(top_countries)]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":687},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1666274895695,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"bMzZ9re_yY5K","outputId":"ae15beb6-006b-46c1-c660-1b53864f01ea"},"outputs":[],"source":["corpus.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666274895695,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"7NsIQrLiSEak","outputId":"22931591-ee49-4ab8-a941-d3dfa3b2127f"},"outputs":[],"source":["corpus.shape"]},{"cell_type":"markdown","metadata":{"id":"1v8oiPAcsqpx"},"source":["# Preprocess documents"]},{"cell_type":"markdown","metadata":{"id":"7psnR5cmQLBx"},"source":["Split data into training, validation, and test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSObnTaWdgdM"},"outputs":[],"source":["training = corpus[corpus[\"testset\"] == 0]\n","validation = training.iloc[80000:100000,]\n","training = training.iloc[0:80000,]\n","test = corpus[corpus[\"testset\"] == 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666274959342,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"m05pjMr8Rvxs","outputId":"c6ce9b40-9b30-449e-b367-04fffe1996fc"},"outputs":[],"source":["print(training.shape)\n","print(validation.shape)\n","print(test.shape)"]},{"cell_type":"markdown","metadata":{"id":"bSrHVdoZsqpy"},"source":["Perform standard NLP preprocessing steps on the training set using spaCy. To speed up things, we disable some components of spaCy's standard NLP pipeline."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sh4KVmP6sqpy"},"outputs":[],"source":["nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n","\n","def spacy_prep_df(corpus):\n","  corpus = corpus.to_dict(\"records\")\n","  for i, entry in enumerate(corpus):\n","      doc = nlp(entry[u'description'])\n","      tokens_to_keep = []\n","      for token in doc:\n","          if token.is_alpha and not token.is_stop:\n","              tokens_to_keep.append(token.lemma_.lower())\n","      entry[u'description_prep'] = \" \".join(tokens_to_keep)\n","  corpus = pd.DataFrame(corpus)\n","  return(corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4rKCZRs9tlj"},"outputs":[],"source":["training = spacy_prep_df(training)"]},{"cell_type":"markdown","metadata":{"id":"9Tothp_Ssqpz"},"source":["Display the first couple of lines of the preprocessed descriptions."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666275448617,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"UyLoiearsqpz","outputId":"220083f2-3d0f-4d20-b30c-3c3896e804cd"},"outputs":[],"source":["training[\"description_prep\"].head()"]},{"cell_type":"markdown","metadata":{"id":"QYQppmeBQUtX"},"source":["# Vectorize documents"]},{"cell_type":"markdown","metadata":{"id":"uAXDnM1Hsqp1"},"source":["Use a `CountVectorizer` to vectorize the documents."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WbeTq9S9sqp1"},"outputs":[],"source":["count_vect = CountVectorizer(min_df=10)"]},{"cell_type":"markdown","metadata":{"id":"06DEGrExsqp1"},"source":["Apply the vectorizer to the review texts of the training set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AemriJOAsqp1"},"outputs":[],"source":["X_training = count_vect.fit_transform(training[\"description_prep\"].tolist())"]},{"cell_type":"markdown","metadata":{"id":"7QTlJ4BDsqp3"},"source":["Store the labels that we want to predict in a separate variable."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1666275450608,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"gUpaU5Pgsqp3","outputId":"5a83d601-83b9-481f-ff66-382b2d893003"},"outputs":[],"source":["y_training = training[\"country\"]\n","y_training.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"Uv9OfHjwE73o"},"source":["A simple way to extend binary classification algorithms to the multi-class classification case is to use the so-called **one-vs-rest scheme**. The simple idea is to learn one binary classifier per class. For doing so, we need to convert multi-class labels to multiple binary labels (i.e., observation belongs or does not belong to the class)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VG6P6mQpDS70"},"outputs":[],"source":["label_bin = LabelBinarizer().fit(y_training)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666275450608,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"vYZTEQ1aEt62","outputId":"ba07ea1f-4039-4d6d-d9a1-8b81031c0a14"},"outputs":[],"source":["y_training_bin = label_bin.transform(y_training)\n","y_training_bin"]},{"cell_type":"markdown","metadata":{"id":"biwWaNjNsqp4"},"source":["# Train classifier on training set"]},{"cell_type":"markdown","metadata":{"id":"WTHaUsAosqp4"},"source":["Use the `OneVsRestClassifier` wrapper to fit one logistic regression classifier per class. The term-document matrix holds the features and the binarized country of origin (i.e., `country` variable) represents the labels."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZkAh7oesqp4"},"outputs":[],"source":["clf = OneVsRestClassifier(LogisticRegression(max_iter=1000)).fit(X_training, y_training_bin)"]},{"cell_type":"markdown","metadata":{"id":"tuAVWgC8sqp4"},"source":["Test whether classifier is working by predicting the quality of a short fake review. We apply the same NLP preprocessing steps and reuse the `count_vect` object to generate features in the same way as we did for the training set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrjU4Uj4-jpx"},"outputs":[],"source":["doc_new = {'index': [1],\n","           'description': ['This wine is nice and easy.']}\n","\n","doc_new_df = pd.DataFrame.from_dict(doc_new)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1666275478788,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"_B16iOiWsqp5","outputId":"48ae6eac-7e51-4d4f-9a31-df51310ea51c"},"outputs":[],"source":["doc_new_df_prep = spacy_prep_df(doc_new_df)\n","doc_new_df_prep"]},{"cell_type":"markdown","metadata":{"id":"cVtvBRIXGktZ"},"source":["Predict class membership."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666275478789,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"6sD7SeyD4nig","outputId":"b4130942-0122-4294-eb4e-ffd98cb97a5e"},"outputs":[],"source":["X_new = count_vect.transform(doc_new_df_prep[\"description_prep\"])\n","predicted = clf.predict(X_new)\n","predicted"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1666275478789,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"9O0CDqPjGtJz","outputId":"3c5b3454-33d8-4c28-9867-9aac86bc5495"},"outputs":[],"source":["label_bin.classes_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666275478789,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"yMp87EJTHfhZ","outputId":"14ca192c-d7fd-4a57-e37f-e2cebc8dbd36"},"outputs":[],"source":["label_bin.inverse_transform(predicted)"]},{"cell_type":"markdown","metadata":{"id":"n6zZzlq4sqp5"},"source":["Instead of predicting hard membership, we can also predict the probabilities of the classes."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1666275478789,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"Ks6yRPyEsqp5","outputId":"2bcf7df6-bad7-4482-d116-2d153ce6acfc"},"outputs":[],"source":["predicted_prob = clf.predict_proba(X_new)\n","print(clf.classes_)\n","print(predicted_prob)"]},{"cell_type":"markdown","metadata":{"id":"663LU5XQsqp5"},"source":["# Evaluate accuracy on validation set"]},{"cell_type":"markdown","metadata":{"id":"K8-z8rqVsqp6"},"source":["Let's evaluate the predictive accurcay of our model on the validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCZDzJOR51SZ"},"outputs":[],"source":["validation = spacy_prep_df(validation)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiUIhoK0sqp6"},"outputs":[],"source":["X_validation = count_vect.transform(validation[\"description_prep\"])\n","y_validation = validation[\"country\"]\n","y_validation_bin = label_bin.transform(y_validation)"]},{"cell_type":"markdown","metadata":{"id":"4upAshmAsqp6"},"source":["Call the predict function of our model with the validation data and calculate precision, recall and F1-score."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1666275576323,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"3Ngkprkgsqp6","outputId":"0b1f5915-34f3-4a55-9634-cfa5e74a1ead"},"outputs":[],"source":["predictions_validation = clf.predict(X_validation)\n","print(metrics.classification_report(y_validation_bin, predictions_validation))"]},{"cell_type":"markdown","metadata":{"id":"XgI1kPv6cKkU"},"source":["# Interpret model"]},{"cell_type":"markdown","metadata":{"id":"6fEkRUPEcPAW"},"source":["Interpretation of a one-vs-rest logistic regression classifier is a bit more complex as usual, as we have to inspect the coefficients of many models (i.e., one per class)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1047,"status":"ok","timestamp":1666275787652,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"5yx40Me_bXdF","outputId":"fc5423f1-ab8c-4237-b524-6a85a0a07e14"},"outputs":[],"source":["coeffs = clf.estimators_[6].coef_.tolist()[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xTsCyZWbokF"},"outputs":[],"source":["words = count_vect.get_feature_names_out()\n","words_with_coeffs = pd.DataFrame(coeffs, words, columns=[\"coeff\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666275787926,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"v21YzlRbb1gI","outputId":"cc6ea901-18f4-4010-ffe3-41eff06e1d34"},"outputs":[],"source":["words_with_coeffs.sort_values(\"coeff\", ascending=True).head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":217,"status":"ok","timestamp":1666275790435,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"3SPNOsuGb45e","outputId":"ec00357e-904c-4301-9082-8405431f4278"},"outputs":[],"source":["words_with_coeffs.sort_values(\"coeff\", ascending=False).head(10)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1kHkaqxz9sVdaOC2i4FJVOOFW9cCiBkYu","timestamp":1635795939236}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}
