{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"DqqfUmU7Rsk_"},"source":["# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"]},{"cell_type":"markdown","metadata":{"id":"LTr0oOHpRuwL"},"source":["# <font color=\"#003660\">Week 1: Basics of Natural Language Processing</font>"]},{"cell_type":"markdown","metadata":{"id":"q21pvAXnqXAF"},"source":["# <font color=\"#003660\">Notebook 2: Conditional Word Counting</font>\n","\n","<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n","\n","<p>\n","<center>\n","<div>\n","    <font color=\"#085986\"><b>By the end of this lesson, you will be able to...</b><br><br>\n","        ... load text data from files and databases,<br> \n","        ... conduct basic NLP preprocessing (e.g., tokenization, stopword removal, stemming, lemmatization),<br>\n","        ... calculate corpus statistics (esp. word frequencies), and<br>\n","        ... calculate and visualize corpus statistics over time.\n","    </font>\n","</div>\n","</center>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"xtu_FbD9qXAJ"},"source":["# Import packages\n","\n","As always, we first need to load a number of required Python packages:\n","- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n","- `NLTK` is a leading platform for building Python programs to work with human language data.\n","- `altair` is a visualization library based on the grammar of graphics."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"BAE0ESOwqXAK","executionInfo":{"status":"ok","timestamp":1665670368395,"user_tz":-120,"elapsed":2010,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}}},"source":["import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","import altair as alt"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mZVcs4V9JOhJ"},"source":["To work with the `NLTK` package, you also need to download some additional data (e.g., stopword lists)."]},{"cell_type":"code","metadata":{"id":"5bljTpl4JPtx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665670369265,"user_tz":-120,"elapsed":877,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}},"outputId":"11a9faab-60d9-4a96-b302-6f05f5ebcf75"},"source":["nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('omw-1.4')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"4PhOPcrmqXAM"},"source":["# Load documents\n","This time, we want to analyze documents with regards to some metadata (i.e., year of publication). Each document is stored in a dictionary with two keys (`text` and `year`). The corpus is stored as a list of dictionaries."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"aV5f4froqXAM","executionInfo":{"status":"ok","timestamp":1665670369266,"user_tz":-120,"elapsed":12,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}}},"source":["corpus = [\n","    {\"text\":\"Hello World\", \"year\":2015},\n","    {\"text\":\"How are you today?\", \"year\":2015},\n","    {\"text\":\"The world is nice\", \"year\":2016},\n","    {\"text\":\"The weather is also nice\", \"year\":2016},\n","    {\"text\":\"Yesterday, the weather was also nice\", \"year\":2017},\n","    {\"text\":\"I own two bicycles\", \"year\":2017},\n","    {\"text\":\"I love to ride my bicycle\", \"year\":2018}\n","]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"rX1cHok_qXAM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665670369267,"user_tz":-120,"elapsed":12,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}},"outputId":"0348a096-16cd-409a-afdd-6c6aea26f21b"},"source":["corpus"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'text': 'Hello World', 'year': 2015},\n"," {'text': 'How are you today?', 'year': 2015},\n"," {'text': 'The world is nice', 'year': 2016},\n"," {'text': 'The weather is also nice', 'year': 2016},\n"," {'text': 'Yesterday, the weather was also nice', 'year': 2017},\n"," {'text': 'I own two bicycles', 'year': 2017},\n"," {'text': 'I love to ride my bicycle', 'year': 2018}]"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"EPv6koXpqXAQ"},"source":["# Preprocess documents"]},{"cell_type":"markdown","metadata":{"id":"3MpKatMPqXAQ"},"source":["We make a copy of the corpus dictionary, iterate over its entries, and add a `tokens` field with the tokenized text."]},{"cell_type":"code","metadata":{"id":"ZISE6qkJqXAR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665670369267,"user_tz":-120,"elapsed":10,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}},"outputId":"765534f5-f765-4cc4-da7c-4f7871ad39fe"},"source":["docs_tokenized = corpus.copy()\n","for i, entry in enumerate(docs_tokenized):\n","    entry[\"tokens\"] = nltk.word_tokenize(entry[\"text\"])\n","docs_tokenized"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'text': 'Hello World', 'year': 2015, 'tokens': ['Hello', 'World']},\n"," {'text': 'How are you today?',\n","  'year': 2015,\n","  'tokens': ['How', 'are', 'you', 'today', '?']},\n"," {'text': 'The world is nice',\n","  'year': 2016,\n","  'tokens': ['The', 'world', 'is', 'nice']},\n"," {'text': 'The weather is also nice',\n","  'year': 2016,\n","  'tokens': ['The', 'weather', 'is', 'also', 'nice']},\n"," {'text': 'Yesterday, the weather was also nice',\n","  'year': 2017,\n","  'tokens': ['Yesterday', ',', 'the', 'weather', 'was', 'also', 'nice']},\n"," {'text': 'I own two bicycles',\n","  'year': 2017,\n","  'tokens': ['I', 'own', 'two', 'bicycles']},\n"," {'text': 'I love to ride my bicycle',\n","  'year': 2018,\n","  'tokens': ['I', 'love', 'to', 'ride', 'my', 'bicycle']}]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"Ef289TzMqXAR"},"source":["And we iterate again over the corpus to transform all tokens to lowercase."]},{"cell_type":"code","metadata":{"id":"kzJtJqo0qXAR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665670369267,"user_tz":-120,"elapsed":7,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}},"outputId":"89799d3b-f1c3-4b7f-e4df-a1333e2ebc64"},"source":["docs_tokenized_lower = docs_tokenized.copy()\n","for i,entry in enumerate(docs_tokenized_lower):\n","    tokens_lower = []\n","    for token in entry[\"tokens\"]:\n","        tokens_lower.append(token.lower())\n","    entry[\"tokens\"] = tokens_lower\n","docs_tokenized_lower"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'text': 'Hello World', 'year': 2015, 'tokens': ['hello', 'world']},\n"," {'text': 'How are you today?',\n","  'year': 2015,\n","  'tokens': ['how', 'are', 'you', 'today', '?']},\n"," {'text': 'The world is nice',\n","  'year': 2016,\n","  'tokens': ['the', 'world', 'is', 'nice']},\n"," {'text': 'The weather is also nice',\n","  'year': 2016,\n","  'tokens': ['the', 'weather', 'is', 'also', 'nice']},\n"," {'text': 'Yesterday, the weather was also nice',\n","  'year': 2017,\n","  'tokens': ['yesterday', ',', 'the', 'weather', 'was', 'also', 'nice']},\n"," {'text': 'I own two bicycles',\n","  'year': 2017,\n","  'tokens': ['i', 'own', 'two', 'bicycles']},\n"," {'text': 'I love to ride my bicycle',\n","  'year': 2018,\n","  'tokens': ['i', 'love', 'to', 'ride', 'my', 'bicycle']}]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"ILTjfiR6qXAS"},"source":["And lemmatize all tokens..."]},{"cell_type":"code","metadata":{"id":"NidxTidPqXAS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665670372341,"user_tz":-120,"elapsed":3079,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}},"outputId":"f638da85-41ff-4ef2-d316-dad88c6114d4"},"source":["lemmatizer = WordNetLemmatizer()\n","\n","docs_tokenized_lower_lemmatized = docs_tokenized_lower.copy()\n","for i,entry in enumerate(docs_tokenized_lower_lemmatized):\n","    tokens_lemmatized = []\n","    for token in entry[\"tokens\"]:\n","        tokens_lemmatized.append(lemmatizer.lemmatize(token))\n","    entry[\"tokens\"] = tokens_lemmatized\n","docs_tokenized_lower_lemmatized"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'text': 'Hello World', 'year': 2015, 'tokens': ['hello', 'world']},\n"," {'text': 'How are you today?',\n","  'year': 2015,\n","  'tokens': ['how', 'are', 'you', 'today', '?']},\n"," {'text': 'The world is nice',\n","  'year': 2016,\n","  'tokens': ['the', 'world', 'is', 'nice']},\n"," {'text': 'The weather is also nice',\n","  'year': 2016,\n","  'tokens': ['the', 'weather', 'is', 'also', 'nice']},\n"," {'text': 'Yesterday, the weather was also nice',\n","  'year': 2017,\n","  'tokens': ['yesterday', ',', 'the', 'weather', 'wa', 'also', 'nice']},\n"," {'text': 'I own two bicycles',\n","  'year': 2017,\n","  'tokens': ['i', 'own', 'two', 'bicycle']},\n"," {'text': 'I love to ride my bicycle',\n","  'year': 2018,\n","  'tokens': ['i', 'love', 'to', 'ride', 'my', 'bicycle']}]"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"aQ-CKFTvqXAT"},"source":["Finally, we iterate one last time over the corpus to remove stopwords."]},{"cell_type":"code","metadata":{"id":"41c8Sw83qXAT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665670372342,"user_tz":-120,"elapsed":25,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}},"outputId":"00f9d252-2c4a-46d6-cdc4-e1ec2751ee53"},"source":["docs_tokenized_lower_lemmatized_cleaned = docs_tokenized_lower_lemmatized.copy()\n","for i,entry in enumerate(docs_tokenized_lower_lemmatized_cleaned):\n","    tokens_cleaned = []\n","    for token in entry[\"tokens\"]:\n","        if (token.isalpha() and token not in stopwords.words('english')):\n","            tokens_cleaned.append(token)\n","    entry[\"tokens\"] = tokens_cleaned\n","docs_tokenized_lower_lemmatized_cleaned"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'text': 'Hello World', 'year': 2015, 'tokens': ['hello', 'world']},\n"," {'text': 'How are you today?', 'year': 2015, 'tokens': ['today']},\n"," {'text': 'The world is nice', 'year': 2016, 'tokens': ['world', 'nice']},\n"," {'text': 'The weather is also nice',\n","  'year': 2016,\n","  'tokens': ['weather', 'also', 'nice']},\n"," {'text': 'Yesterday, the weather was also nice',\n","  'year': 2017,\n","  'tokens': ['yesterday', 'weather', 'wa', 'also', 'nice']},\n"," {'text': 'I own two bicycles', 'year': 2017, 'tokens': ['two', 'bicycle']},\n"," {'text': 'I love to ride my bicycle',\n","  'year': 2018,\n","  'tokens': ['love', 'ride', 'bicycle']}]"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"uXXYgWwBqXAT"},"source":["# Conditional word counting\n","We seperately count words for each condition, that is, for each year. Unfortunately, this time we have to do this \"by hand\" and iterate through all docs and tokens and increase the token count for the respective condition."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"PPKYDzHDqXAU","executionInfo":{"status":"ok","timestamp":1665670372342,"user_tz":-120,"elapsed":21,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}}},"source":["cfreq = nltk.ConditionalFreqDist()\n","\n","for doc in docs_tokenized_lower_lemmatized_cleaned:\n","    for token in doc[\"tokens\"]:\n","        condition = doc[\"year\"]\n","        cfreq[condition][token] += 1"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dcx6_55RqXAU"},"source":["Print the frequency distributions for all conditions."]},{"cell_type":"code","metadata":{"id":"3z0dXrb3qXAU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665670372343,"user_tz":-120,"elapsed":22,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}},"outputId":"36cfe2c0-ecc5-4dfb-dbcc-ba4f9d532e38"},"source":["cfreq"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<ConditionalFreqDist with 4 conditions>"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"DWHOlBB_qXAV"},"source":["Print the frequency distributions of the year 2017."]},{"cell_type":"code","metadata":{"id":"3zejWM_dqXAV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665670852858,"user_tz":-120,"elapsed":2,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}},"outputId":"1d07dce7-2890-4132-908d-47cc32a1af90"},"source":["cfreq[2017]"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FreqDist({'yesterday': 1, 'weather': 1, 'wa': 1, 'also': 1, 'nice': 1, 'two': 1, 'bicycle': 1})"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"34QLgxiTKlVN"},"source":["# Time series of word occurences"]},{"cell_type":"markdown","metadata":{"id":"vi0AhH7mqXAV"},"source":["For all years between 2015 and 2018, get the frequency of the word \"nice\"."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"PKo19RFMqXAX","executionInfo":{"status":"ok","timestamp":1665670864104,"user_tz":-120,"elapsed":214,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}}},"source":["word = \"nice\"\n","years = range(2015,2019)\n","occurences = []\n","for year in years:\n","    occurences.append(cfreq[year][word])"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r0X4jlZ0qXAX"},"source":["Print the resulting time series."]},{"cell_type":"code","metadata":{"id":"YDcL0Ed5qXAX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665670866247,"user_tz":-120,"elapsed":3,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}},"outputId":"49c5375b-2067-4727-ced3-c12fdca50403"},"source":["occurences"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 2, 1, 0]"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"EZYCBOauK4oK"},"source":["Zip the years and the word occurcences in one dataframe."]},{"cell_type":"code","metadata":{"id":"uG4vql4MK3rM","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"ok","timestamp":1665670869862,"user_tz":-120,"elapsed":223,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}},"outputId":"e276fb27-f34f-44e6-998d-2ec021722f53"},"source":["timeseries = pd.DataFrame(list(zip(years, occurences)),\n","              columns=['years','count'])\n","timeseries['years'] = pd.to_datetime(timeseries['years'], format='%Y')\n","timeseries"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       years  count\n","0 2015-01-01      0\n","1 2016-01-01      2\n","2 2017-01-01      1\n","3 2018-01-01      0"],"text/html":["\n","  <div id=\"df-7637ef7c-7046-44a2-bbe9-7ad6deb294fd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>years</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2015-01-01</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2016-01-01</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-01-01</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2018-01-01</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7637ef7c-7046-44a2-bbe9-7ad6deb294fd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7637ef7c-7046-44a2-bbe9-7ad6deb294fd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7637ef7c-7046-44a2-bbe9-7ad6deb294fd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"_UGGmV3kqXAX"},"source":["Plot the time series."]},{"cell_type":"code","metadata":{"id":"IPP0bsYaqXAY","colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"status":"ok","timestamp":1665670876231,"user_tz":-120,"elapsed":257,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}},"outputId":"e8c03948-f1fb-4ddd-a47f-4d2e899948e1"},"source":["alt.Chart(timeseries).mark_line().encode(\n","    x='years',\n","    y='count'\n",").interactive()"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","<div id=\"altair-viz-3e176c1375e04f648c009c04015a970f\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-3e176c1375e04f648c009c04015a970f\") {\n","      outputDiv = document.getElementById(\"altair-viz-3e176c1375e04f648c009c04015a970f\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-4da068fa586e81def5a33f7b2f2e0336\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"field\": \"years\", \"type\": \"temporal\"}, \"y\": {\"field\": \"count\", \"type\": \"quantitative\"}}, \"selection\": {\"selector002\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-4da068fa586e81def5a33f7b2f2e0336\": [{\"years\": \"2015-01-01T00:00:00\", \"count\": 0}, {\"years\": \"2016-01-01T00:00:00\", \"count\": 2}, {\"years\": \"2017-01-01T00:00:00\", \"count\": 1}, {\"years\": \"2018-01-01T00:00:00\", \"count\": 0}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":[],"metadata":{"id":"Ea_TS3dUZqug","executionInfo":{"status":"ok","timestamp":1665670372346,"user_tz":-120,"elapsed":15,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"}}},"execution_count":15,"outputs":[]}]}