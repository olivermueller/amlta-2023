{"cells":[{"cell_type":"markdown","metadata":{"id":"LJrKCbjZsqpo"},"source":["# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"]},{"cell_type":"markdown","metadata":{"id":"V-DU0hkyVyPi"},"source":["# <font color=\"#003660\">Session 1: Introduction to Natural Language Processing</font>"]},{"cell_type":"markdown","metadata":{"id":"mhy42GjRV3ON"},"source":["# <font color=\"#003660\">Notebook 2: Binary Classification</font>\n","\n","<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n","\n","<p>\n","<center>\n","<div>\n","    <font color=\"#085986\"><b>By the end of this lesson, you will be able to...</b><br><br>\n","        ... transform raw text into a term-document matrix, <br>\n","        ... train a binary classifier on the term-document matrix, and <br> ... and compete in a Kaggle competition.\n","    </font>\n","</div>\n","</center>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"C6vVpwIFsqps"},"source":["# Import packages\n","\n","As always, we first need to load a number of required Python packages:\n","- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n","- `SQLAlchemy`, together with `pymysql`, allows to communicate with SQL databases.\n","- `getpass` provides function to safely enter passwords.\n","- `spacy` offers industrial-strength natural language processing.\n","- `sklearn` is the de-facto standard machine learning package in Python."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8587,"status":"ok","timestamp":1666269211355,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"5NpTS4Z2Vvzy","outputId":"3adda4ba-72a3-45d1-ba70-1350efd228ba"},"outputs":[],"source":["# Install packages\n","#!pip install pymysql"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"mMrhkr83sqpt"},"outputs":[],"source":["import pandas as pd\n","from sqlalchemy import create_engine, text\n","import getpass\n","import spacy\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import metrics\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"markdown","metadata":{"id":"jZd82t53sqpu"},"source":["# Load documents"]},{"cell_type":"markdown","metadata":{"id":"IsrCafxksqpv"},"source":["We load our data from a MySQL database. For security reasons, we don't store the database credentials here; please have a look at Panda to get them."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26542,"status":"ok","timestamp":1666269247369,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"vSIGfKcXsqpv","outputId":"208240ba-c7d4-4322-c693-f5d68ad6a922"},"outputs":[],"source":["# Get credentials\n","user = input(\"Username: \")\n","passwd = getpass.getpass(\"Password: \")\n","server = input(\"Server: \")\n","db = input(\"Database: \")\n","\n","# Create an engine instance (SQLAlchemy)\n","engine = create_engine(\"mysql+pymysql://{}:{}@{}/{}\".format(user, passwd ,server, db))\n","\n","# Define SQL query\n","sql_query = \"SELECT * FROM WineDataset\"\n","\n","# Query dataset (pandas)\n","corpus = pd.DataFrame(engine.connect().execute(text(sql_query)))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":687},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666269247369,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"bMzZ9re_yY5K","outputId":"7f61bd27-df93-4057-eff7-f63684e6fc72"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>country</th>\n","      <th>description</th>\n","      <th>designation</th>\n","      <th>points</th>\n","      <th>price</th>\n","      <th>province</th>\n","      <th>region_1</th>\n","      <th>region_2</th>\n","      <th>taster_name</th>\n","      <th>taster_twitter_handle</th>\n","      <th>title</th>\n","      <th>variety</th>\n","      <th>winery</th>\n","      <th>testset</th>\n","      <th>verygood</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Italy</td>\n","      <td>Aromas include tropical fruit, broom, brimston...</td>\n","      <td>Vulkà Bianco</td>\n","      <td>87</td>\n","      <td>NaN</td>\n","      <td>Sicily &amp; Sardinia</td>\n","      <td>Etna</td>\n","      <td>None</td>\n","      <td>Kerin O’Keefe</td>\n","      <td>@kerinokeefe</td>\n","      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n","      <td>White Blend</td>\n","      <td>Nicosia</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Portugal</td>\n","      <td>This is ripe and fruity, a wine that is smooth...</td>\n","      <td>Avidagos</td>\n","      <td>87</td>\n","      <td>15.0</td>\n","      <td>Douro</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>Roger Voss</td>\n","      <td>@vossroger</td>\n","      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n","      <td>Portuguese Red</td>\n","      <td>Quinta dos Avidagos</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>US</td>\n","      <td>Tart and snappy, the flavors of lime flesh and...</td>\n","      <td>None</td>\n","      <td>87</td>\n","      <td>14.0</td>\n","      <td>Oregon</td>\n","      <td>Willamette Valley</td>\n","      <td>Willamette Valley</td>\n","      <td>Paul Gregutt</td>\n","      <td>@paulgwine</td>\n","      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n","      <td>Pinot Gris</td>\n","      <td>Rainstorm</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>US</td>\n","      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n","      <td>Reserve Late Harvest</td>\n","      <td>87</td>\n","      <td>13.0</td>\n","      <td>Michigan</td>\n","      <td>Lake Michigan Shore</td>\n","      <td>None</td>\n","      <td>Alexander Peartree</td>\n","      <td>None</td>\n","      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n","      <td>Riesling</td>\n","      <td>St. Julian</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>US</td>\n","      <td>Much like the regular bottling from 2012, this...</td>\n","      <td>Vintner's Reserve Wild Child Block</td>\n","      <td>87</td>\n","      <td>65.0</td>\n","      <td>Oregon</td>\n","      <td>Willamette Valley</td>\n","      <td>Willamette Valley</td>\n","      <td>Paul Gregutt</td>\n","      <td>@paulgwine</td>\n","      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n","      <td>Pinot Noir</td>\n","      <td>Sweet Cheeks</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index   country                                        description  \\\n","0      0     Italy  Aromas include tropical fruit, broom, brimston...   \n","1      1  Portugal  This is ripe and fruity, a wine that is smooth...   \n","2      2        US  Tart and snappy, the flavors of lime flesh and...   \n","3      3        US  Pineapple rind, lemon pith and orange blossom ...   \n","4      4        US  Much like the regular bottling from 2012, this...   \n","\n","                          designation  points  price           province  \\\n","0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n","1                            Avidagos      87   15.0              Douro   \n","2                                None      87   14.0             Oregon   \n","3                Reserve Late Harvest      87   13.0           Michigan   \n","4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n","\n","              region_1           region_2         taster_name  \\\n","0                 Etna               None       Kerin O’Keefe   \n","1                 None               None          Roger Voss   \n","2    Willamette Valley  Willamette Valley        Paul Gregutt   \n","3  Lake Michigan Shore               None  Alexander Peartree   \n","4    Willamette Valley  Willamette Valley        Paul Gregutt   \n","\n","  taster_twitter_handle                                              title  \\\n","0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n","1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n","2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n","3                  None  St. Julian 2013 Reserve Late Harvest Riesling ...   \n","4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n","\n","          variety               winery  testset  verygood  \n","0     White Blend              Nicosia        0         0  \n","1  Portuguese Red  Quinta dos Avidagos        0         0  \n","2      Pinot Gris            Rainstorm        0         0  \n","3        Riesling           St. Julian        0         0  \n","4      Pinot Noir         Sweet Cheeks        0         0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["corpus.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322,"status":"ok","timestamp":1666269247689,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"7NsIQrLiSEak","outputId":"274be739-6a25-448e-a0d2-8702bb598576"},"outputs":[{"data":{"text/plain":["(129971, 16)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["corpus.shape"]},{"cell_type":"markdown","metadata":{"id":"1v8oiPAcsqpx"},"source":["# Preprocess documents"]},{"cell_type":"markdown","metadata":{"id":"7psnR5cmQLBx"},"source":["Split data into training, validation, and test set."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"uSObnTaWdgdM"},"outputs":[],"source":["training = corpus[corpus[\"testset\"] == 0]\n","validation = training.iloc[80000:100000,]\n","training = training.iloc[0:80000,]\n","test = corpus[corpus[\"testset\"] == 1]"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666269440366,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"m05pjMr8Rvxs","outputId":"aeed0594-90ff-4fe2-9362-462b8874376f"},"outputs":[{"name":"stdout","output_type":"stream","text":["(80000, 16)\n","(20000, 16)\n","(29970, 16)\n"]}],"source":["print(training.shape)\n","print(validation.shape)\n","print(test.shape)"]},{"cell_type":"markdown","metadata":{"id":"bSrHVdoZsqpy"},"source":["Perform standard NLP preprocessing steps on the training set using spaCy. To speed up things, we disable some components of spaCy's standard NLP pipeline."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"sh4KVmP6sqpy"},"outputs":[],"source":["# YOUR CODE GOES HERE!\n","nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n"," \n","def spacy_prep_df(corpus):\n","  corpus = corpus.to_dict(\"records\")\n","  for i, entry in enumerate(corpus):\n","    doc = nlp(entry[u\"description\"])\n","    tokens_to_keep = []\n","    for token in doc:\n","      if token.is_alpha and not token.is_stop:\n","        tokens_to_keep.append(token.lemma_.lower())\n","    entry[u\"description_prep\"] = \" \".join(tokens_to_keep)\n","  corpus = pd.DataFrame(corpus)\n","  return(corpus)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"I4rKCZRs9tlj"},"outputs":[],"source":["training = spacy_prep_df(training)"]},{"cell_type":"markdown","metadata":{"id":"9Tothp_Ssqpz"},"source":["Display the first couple of lines of the preprocessed descriptions."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235,"status":"ok","timestamp":1666270637484,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"UyLoiearsqpz","outputId":"c1a8fffa-cc0b-4120-b14a-b1784806d981"},"outputs":[{"data":{"text/plain":["0    aromas include tropical fruit broom brimstone ...\n","1    ripe fruity wine smooth structure firm tannin ...\n","2    tart snappy flavor lime flesh rind dominate gr...\n","3    pineapple rind lemon pith orange blossom start...\n","4    like regular bottling come rough tannic rustic...\n","Name: description_prep, dtype: object"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["training[\"description_prep\"].head()"]},{"cell_type":"markdown","metadata":{"id":"QYQppmeBQUtX"},"source":["# Vectorize documents"]},{"cell_type":"markdown","metadata":{"id":"uAXDnM1Hsqp1"},"source":["Vectorization is the process of turning a collection of text documents into numerical feature vectors.\n","\n","We will use the **Bag of Words (BoW)** model for vectorization. In the BoW model, a corpus of documents is represented by a matrix with one row per document and one column per word occurring in the corpus. The cell values will either be simple frequency counts (How often does a word appear in a document?), or the term frequency (tf) times the inverse document frequency (idf) of a term. The idea of tf-idf is to scale down the impact of words that occur very frequently in a given corpus and that are therefore less informative than features that occur only in a small fraction of the corpus. Note that the BoW model completely ignores information about the position and sequences of the words in the document.\n","\n","In `sklearn`, the [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) creates a term-document matrix with (normalized) term frequencies and the [`TfIdfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) creates a term-document matrix with tf-idf weighting."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"WbeTq9S9sqp1"},"outputs":[],"source":["count_vect = CountVectorizer(min_df=10)"]},{"cell_type":"markdown","metadata":{"id":"06DEGrExsqp1"},"source":["Apply the CountVectorizer object to the review texts of the training set."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"AemriJOAsqp1"},"outputs":[],"source":["X_training = count_vect.fit_transform(training[\"description_prep\"].tolist())"]},{"cell_type":"markdown","metadata":{"id":"1OV17A_2sqp2"},"source":["Display an extract of the generated term-document matrix"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1666270941802,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"vLq7fYBy3J2q","outputId":"031fef17-71e1-4d99-c36a-dd48939fa6ed"},"outputs":[{"data":{"text/plain":["(80000, 5646)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["X_training.shape"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1666270948540,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"ANQd_dVlsqp2","outputId":"639aa9c4-08fc-46ab-a637-2ad950e9b8b3"},"outputs":[{"data":{"text/plain":["matrix([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["X_training[0:20,0:20].todense()"]},{"cell_type":"markdown","metadata":{"id":"7QTlJ4BDsqp3"},"source":["Store the labels that we want to predict in a separate variable."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":240,"status":"ok","timestamp":1666271013159,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"gUpaU5Pgsqp3","outputId":"245d8d8c-e92f-4cc8-d350-eb81413ab6b9"},"outputs":[{"data":{"text/plain":["count    80000.000000\n","mean         0.095137\n","std          0.293407\n","min          0.000000\n","25%          0.000000\n","50%          0.000000\n","75%          0.000000\n","max          1.000000\n","Name: verygood, dtype: float64"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["y_training = training[\"verygood\"]\n","y_training.describe()"]},{"cell_type":"markdown","metadata":{"id":"biwWaNjNsqp4"},"source":["# Train classifier on training set"]},{"cell_type":"markdown","metadata":{"id":"WTHaUsAosqp4"},"source":["Fit a logistic regression classification with the term-document matrix as the features and the wine quality (i.e., `verygood` variable) as the label."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"YZkAh7oesqp4"},"outputs":[],"source":["clf = LogisticRegression(max_iter=1000).fit(X_training, y_training)"]},{"cell_type":"markdown","metadata":{"id":"tuAVWgC8sqp4"},"source":["Test whether classifier is working by predicting the quality of a short fake review. We apply the same NLP preprocessing steps and reuse the `count_vect` object to generate features in the same way as we did for the training set."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"WrjU4Uj4-jpx"},"outputs":[],"source":["doc_new = {'index': [1],\n","           'description': ['This is a spectacular, magnificent, and majestic wine. Awesome!']}\n","\n","doc_new_df = pd.DataFrame.from_dict(doc_new)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666271286359,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"_B16iOiWsqp5","outputId":"977e054f-0750-4753-d04f-2d9aa4dfb19c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>description</th>\n","      <th>description_prep</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>This is a spectacular, magnificent, and majest...</td>\n","      <td>spectacular magnificent majestic wine awesome</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index                                        description  \\\n","0      1  This is a spectacular, magnificent, and majest...   \n","\n","                                description_prep  \n","0  spectacular magnificent majestic wine awesome  "]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["doc_new_df_prep = spacy_prep_df(doc_new_df)\n","doc_new_df_prep"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666271286359,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"6sD7SeyD4nig","outputId":"0de40203-fd29-4095-80dd-03d5bbbeacc2"},"outputs":[{"data":{"text/plain":["array([1])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["X_new = count_vect.transform(doc_new_df_prep[\"description_prep\"])\n","predicted = clf.predict(X_new)\n","predicted"]},{"cell_type":"markdown","metadata":{"id":"n6zZzlq4sqp5"},"source":["Instead of predicting binary labels, we can also predict probabilities of the classes."]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666271289647,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"Ks6yRPyEsqp5","outputId":"5c9b30c2-c5f8-48d4-c53a-7c7bd4e20e21"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1]\n","[[0.12983296 0.87016704]]\n"]}],"source":["predicted_prob = clf.predict_proba(X_new)\n","print(clf.classes_)\n","print(predicted_prob)"]},{"cell_type":"markdown","metadata":{"id":"663LU5XQsqp5"},"source":["# Evaluate accuracy on validation set"]},{"cell_type":"markdown","metadata":{"id":"K8-z8rqVsqp6"},"source":["Before trying to predict the labels for the official test set, we evaluate the predictive accurcay of our model on the validation set. Again, we apply the same NLP preprocessing steps, reuse the `count_vect` object, and store `X` and `y` in separate data structures."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"mCZDzJOR51SZ"},"outputs":[],"source":["validation = spacy_prep_df(validation)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"eiUIhoK0sqp6"},"outputs":[],"source":["X_validation = count_vect.transform(validation[\"description_prep\"])\n","y_validation = validation[\"verygood\"]"]},{"cell_type":"markdown","metadata":{"id":"4upAshmAsqp6"},"source":["Call the predict function of our model with the validation data and calculate precision, recall and F1-score."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1666271420302,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"3Ngkprkgsqp6","outputId":"2713b37d-c8e3-4c95-f9ee-39e2eef82b4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.94      0.98      0.96     18001\n","           1       0.67      0.44      0.53      1999\n","\n","    accuracy                           0.92     20000\n","   macro avg       0.80      0.71      0.74     20000\n","weighted avg       0.91      0.92      0.91     20000\n","\n"]}],"source":["predictions_validation = clf.predict(X_validation)\n","print(metrics.classification_report(y_validation, predictions_validation))"]},{"cell_type":"markdown","metadata":{"id":"sOCv-dHNsqp6"},"source":["# Interpret model"]},{"cell_type":"markdown","metadata":{"id":"oB06C4vFsqp7"},"source":["Logistic regression is typically not the most accurate classification model, but one big advantage is that it can be interpreted by looking at the coefficients of the input features."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"EOHsVlNGsqp7"},"outputs":[],"source":["coeffs = clf.coef_[0].tolist()\n","words = count_vect.get_feature_names_out()\n","words_with_coeffs = pd.DataFrame(coeffs, words, columns=[\"coeff\"])"]},{"cell_type":"markdown","metadata":{"id":"gaHsYC1xsqp7"},"source":["These are the words with the most *negative* impact.    "]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1666271501133,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"uc6X4kaFsqp7","outputId":"cc0ded9c-0c54-4958-e6eb-d4a2345780d3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>coeff</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pinotage</th>\n","      <td>-1.963521</td>\n","    </tr>\n","    <tr>\n","      <th>gewürztraminer</th>\n","      <td>-1.858959</td>\n","    </tr>\n","    <tr>\n","      <th>host</th>\n","      <td>-1.794522</td>\n","    </tr>\n","    <tr>\n","      <th>barbera</th>\n","      <td>-1.733643</td>\n","    </tr>\n","    <tr>\n","      <th>fish</th>\n","      <td>-1.647660</td>\n","    </tr>\n","    <tr>\n","      <th>michigan</th>\n","      <td>-1.626705</td>\n","    </tr>\n","    <tr>\n","      <th>spoil</th>\n","      <td>-1.557407</td>\n","    </tr>\n","    <tr>\n","      <th>easygoing</th>\n","      <td>-1.508513</td>\n","    </tr>\n","    <tr>\n","      <th>value</th>\n","      <td>-1.489763</td>\n","    </tr>\n","    <tr>\n","      <th>prevail</th>\n","      <td>-1.480937</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   coeff\n","pinotage       -1.963521\n","gewürztraminer -1.858959\n","host           -1.794522\n","barbera        -1.733643\n","fish           -1.647660\n","michigan       -1.626705\n","spoil          -1.557407\n","easygoing      -1.508513\n","value          -1.489763\n","prevail        -1.480937"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["words_with_coeffs.sort_values(\"coeff\", ascending=True).head(10)"]},{"cell_type":"markdown","metadata":{"id":"xo2Zz0qrsqp8"},"source":["And these are the words with the most *positive* impact."]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":351,"status":"ok","timestamp":1666271540487,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"FBYjvIJnsqp8","outputId":"5d850670-4b10-424b-d12c-24364131d792"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>coeff</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>clendenen</th>\n","      <td>2.427851</td>\n","    </tr>\n","    <tr>\n","      <th>spectacular</th>\n","      <td>2.359522</td>\n","    </tr>\n","    <tr>\n","      <th>sample</th>\n","      <td>2.247237</td>\n","    </tr>\n","    <tr>\n","      <th>magnificent</th>\n","      <td>2.046767</td>\n","    </tr>\n","    <tr>\n","      <th>stunning</th>\n","      <td>2.009384</td>\n","    </tr>\n","    <tr>\n","      <th>cornas</th>\n","      <td>1.989297</td>\n","    </tr>\n","    <tr>\n","      <th>endless</th>\n","      <td>1.971561</td>\n","    </tr>\n","    <tr>\n","      <th>immensely</th>\n","      <td>1.966098</td>\n","    </tr>\n","    <tr>\n","      <th>extraordinary</th>\n","      <td>1.922673</td>\n","    </tr>\n","    <tr>\n","      <th>majestic</th>\n","      <td>1.918256</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  coeff\n","clendenen      2.427851\n","spectacular    2.359522\n","sample         2.247237\n","magnificent    2.046767\n","stunning       2.009384\n","cornas         1.989297\n","endless        1.971561\n","immensely      1.966098\n","extraordinary  1.922673\n","majestic       1.918256"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["words_with_coeffs.sort_values(\"coeff\", ascending=False).head(10)"]},{"cell_type":"markdown","metadata":{"id":"EK-kUHvqUT7H"},"source":["# Make predictions on test set"]},{"cell_type":"markdown","metadata":{"id":"KOAiyw6_5ZJn"},"source":["Preprocess and vectorize the review texts of the test set."]},{"cell_type":"code","execution_count":29,"metadata":{"id":"ljCV8CjF5m-B"},"outputs":[],"source":["test = spacy_prep_df(test)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"GKxkVjlsUXCQ"},"outputs":[],"source":["X_test = count_vect.transform(test[\"description_prep\"])\n","predictions_test = clf.predict(X_test)"]},{"cell_type":"markdown","metadata":{"id":"VnUWSu8N5oZN"},"source":["Create a dataframe with the indices and predictions and save it as a CSV file (which we can upload to Kaggle)."]},{"cell_type":"code","execution_count":31,"metadata":{"id":"dTBW2SnMUkjm"},"outputs":[],"source":["my_submission = pd.DataFrame({'index': test[\"index\"],\n","                              'verygood': predictions_test})"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666271767446,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"VKwZ8MIcVAjl","outputId":"7b430a7d-e926-4506-9b38-4fe94f1f658f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>verygood</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>100001</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100002</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>100003</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>100004</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>100005</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    index  verygood\n","0  100001         1\n","1  100002         0\n","2  100003         0\n","3  100004         0\n","4  100005         1"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["my_submission.head()"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"EzQ2NzHyVvGB"},"outputs":[],"source":["my_submission.to_csv(\"my_submission.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"4NHp_iYqX2Ob"},"source":["# Define a pipeline and tune the model"]},{"cell_type":"markdown","metadata":{"id":"JW59HxdX60bd"},"source":["Typically, we want to try out different preprocessing strategies and/or different classification algorithms. The concept of a **pipeline** in `sklearn` is very usuful to streamline this process.\n","\n","The purpose of a pipeline is to bundle several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a `__`, as in the example below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGl_loPlZjJz"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","clf_pipe = Pipeline([\n","    ('vect', CountVectorizer()),\n","    ('clf', RandomForestClassifier()),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bydgFnF9ZjFc"},"outputs":[],"source":["parameters = {\n","    'vect__min_df': (10,100)\n","}"]},{"cell_type":"markdown","metadata":{"id":"Vlvsvhdp7Ty0"},"source":["With the pipeline and its parameters, it is possible to run an exhaustive search of the best parameters on a grid of possible values and evaluate their effects on the predictive accuracy using k-fold cross validation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zM1CqR7wZrEb"},"outputs":[],"source":["clf_pipe_gs = GridSearchCV(clf_pipe, parameters, cv=3, scoring=\"f1_macro\", n_jobs=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-iyvUPMZuw_"},"outputs":[],"source":["clf_pipe_gs = clf_pipe_gs.fit(training[\"description_prep\"], training[\"verygood\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-wgKe0FabXj"},"outputs":[],"source":["pd.DataFrame(clf_pipe_gs.cv_results_)"]},{"cell_type":"markdown","metadata":{"id":"SaeEi9Wd773N"},"source":["After the grid search has been performed and the best parameter values have been determined, we can use the fitted pipeline object just like a normal model (e.g., call the predict method with new data)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcdAFAMgaFot"},"outputs":[],"source":["predictions_validation = clf_pipe_gs.predict(validation[\"description_prep\"])\n","print(metrics.classification_report(validation[\"verygood\"], predictions_validation))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uu2VTatR9DuV"},"outputs":[],"source":["predictions_test = clf_pipe_gs.predict(test[\"description_prep\"])\n","my_submission = pd.DataFrame({'index': test[\"index\"],\n","                              'verygood':predictions_test})\n","my_submission.to_csv(\"my_submission.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"aFi7MHRIX5v7"},"source":["For more tips and tricks on parameter tuning using grid search for text data, see: [https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
