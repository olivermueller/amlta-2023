{"cells":[{"cell_type":"markdown","metadata":{"id":"LJrKCbjZsqpo"},"source":["# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"]},{"cell_type":"markdown","metadata":{"id":"V-DU0hkyVyPi"},"source":["# <font color=\"#003660\">Week 1: Introduction to Natural Language Processing</font>"]},{"cell_type":"markdown","metadata":{"id":"mhy42GjRV3ON"},"source":["# <font color=\"#003660\">Notebook 3: Regression</font>\n","\n","<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n","\n","<p>\n","<center>\n","<div>\n","    <font color=\"#085986\"><b>By the end of this lesson, you will be able to...</b><br><br>\n","        ... transform raw text into a term-document matrix, <br>\n","        ... train a regression model on the term-document matrix, and <br> ... and compete in a Kaggle competition.\n","    </font>\n","</div>\n","</center>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"C6vVpwIFsqps"},"source":["# Import packages\n","\n","As always, we first need to load a number of required Python packages:\n","- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n","- `SQLAlchemy`, together with `pymysql`, allows to communicate with SQL databases.\n","- `getpass` provides function to safely enter passwords.\n","- `spacy` offers industrial-strength natural language processing.\n","- `sklearn` is the de-facto standard machine learning package in Python."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NpTS4Z2Vvzy"},"outputs":[],"source":["# Install packages\n","!pip install pymysql"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMrhkr83sqpt"},"outputs":[],"source":["import pandas as pd\n","from sqlalchemy import create_engine, text\n","import getpass\n","import spacy\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LinearRegression\n","from sklearn import metrics\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"markdown","metadata":{"id":"jZd82t53sqpu"},"source":["# Load documents"]},{"cell_type":"markdown","metadata":{"id":"IsrCafxksqpv"},"source":["We load our data from a MySQL database. For security reasons, we don't store the database credentials here; please have a look at Panda to get them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vSIGfKcXsqpv"},"outputs":[],"source":["# Get credentials\n","user = input(\"Username: \")\n","passwd = getpass.getpass(\"Password: \")\n","server = input(\"Server: \")\n","db = input(\"Database: \")\n","\n","# Create an engine instance (SQLAlchemy)\n","engine = create_engine(\"mysql+pymysql://{}:{}@{}/{}\".format(user, passwd ,server, db))\n","\n","# Define SQL query\n","sql_query = \"SELECT * FROM WineDataset\"\n","\n","# Query dataset (pandas)\n","corpus = pd.DataFrame(engine.connect().execute(text(sql_query)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMzZ9re_yY5K"},"outputs":[],"source":["corpus.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7NsIQrLiSEak"},"outputs":[],"source":["corpus.shape"]},{"cell_type":"markdown","metadata":{"id":"1v8oiPAcsqpx"},"source":["# Preprocess documents"]},{"cell_type":"markdown","metadata":{"id":"7psnR5cmQLBx"},"source":["Split data into training, validation, and test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSObnTaWdgdM"},"outputs":[],"source":["training = corpus[corpus[\"testset\"] == 0]\n","validation = training.iloc[80000:100000,]\n","training = training.iloc[0:80000,]\n","test = corpus[corpus[\"testset\"] == 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m05pjMr8Rvxs"},"outputs":[],"source":["print(training.shape)\n","print(validation.shape)\n","print(test.shape)"]},{"cell_type":"markdown","metadata":{"id":"bSrHVdoZsqpy"},"source":["Perform standard NLP preprocessing steps on the training set using spaCy. To speed up things, we disable some components of spaCy's standard NLP pipeline."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sh4KVmP6sqpy"},"outputs":[],"source":["nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n","\n","def spacy_prep_df(corpus):\n","  corpus = corpus.to_dict(\"records\")\n","  for i, entry in enumerate(corpus):\n","      doc = nlp(entry[u'description'])\n","      tokens_to_keep = []\n","      for token in doc:\n","          if token.is_alpha and not token.is_stop:\n","              tokens_to_keep.append(token.lemma_.lower())\n","      entry[u'description_prep'] = \" \".join(tokens_to_keep)\n","  corpus = pd.DataFrame(corpus)\n","  return(corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4rKCZRs9tlj"},"outputs":[],"source":["training = spacy_prep_df(training)"]},{"cell_type":"markdown","metadata":{"id":"9Tothp_Ssqpz"},"source":["Display the first couple of lines of the preprocessed descriptions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UyLoiearsqpz"},"outputs":[],"source":["training[\"description_prep\"].head()"]},{"cell_type":"markdown","metadata":{"id":"QYQppmeBQUtX"},"source":["# Vectorize documents"]},{"cell_type":"markdown","metadata":{"id":"uAXDnM1Hsqp1"},"source":["Vectorize using a simple `CountVectorizer`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WbeTq9S9sqp1"},"outputs":[],"source":["count_vect = CountVectorizer(min_df=10)"]},{"cell_type":"markdown","metadata":{"id":"06DEGrExsqp1"},"source":["Apply the CountVectorizer object to the review texts of the training set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AemriJOAsqp1"},"outputs":[],"source":["X_training = count_vect.fit_transform(training[\"description_prep\"].tolist())"]},{"cell_type":"markdown","metadata":{"id":"7QTlJ4BDsqp3"},"source":["Store the labels that we want to predict in a separate variable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUpaU5Pgsqp3"},"outputs":[],"source":["y_training = training[\"points\"]\n","y_training.describe()"]},{"cell_type":"markdown","metadata":{"id":"biwWaNjNsqp4"},"source":["# Train regressor on training set"]},{"cell_type":"markdown","metadata":{"id":"WTHaUsAosqp4"},"source":["Fit a linear regression model with the term-document matrix as the features and the numeric wine quality (i.e., `points` variable) as the label."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZkAh7oesqp4"},"outputs":[],"source":["reg = LinearRegression().fit(X_training, y_training)"]},{"cell_type":"markdown","metadata":{"id":"tuAVWgC8sqp4"},"source":["Test whether model is working by predicting the quality of a short fake review."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrjU4Uj4-jpx"},"outputs":[],"source":["doc_new = {'index': [1],\n","           'description': ['This is a good wine']}\n","\n","doc_new_df = pd.DataFrame.from_dict(doc_new)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_B16iOiWsqp5"},"outputs":[],"source":["doc_new_df_prep = spacy_prep_df(doc_new_df)\n","doc_new_df_prep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6sD7SeyD4nig"},"outputs":[],"source":["X_new = count_vect.transform(doc_new_df_prep[\"description_prep\"])\n","predicted = reg.predict(X_new)\n","predicted"]},{"cell_type":"markdown","metadata":{"id":"663LU5XQsqp5"},"source":["# Evaluate accuracy on validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCZDzJOR51SZ"},"outputs":[],"source":["validation = spacy_prep_df(validation)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiUIhoK0sqp6"},"outputs":[],"source":["X_validation = count_vect.transform(validation[\"description_prep\"])\n","y_validation = validation[\"points\"]"]},{"cell_type":"markdown","metadata":{"id":"1AodM56XE3TT"},"source":["Before calculating the predictions of our model, let's first create a simple benchmark (i.e., always predicting the mean points of the training set)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"61O-npO7CEvn"},"outputs":[],"source":["print(metrics.mean_absolute_error(y_validation, [88.43]*len(y_validation)))"]},{"cell_type":"markdown","metadata":{"id":"4upAshmAsqp6"},"source":["Call the predict function of our model with the validation data and calculate MAE."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Ngkprkgsqp6"},"outputs":[],"source":["predictions_validation = reg.predict(X_validation)\n","print(metrics.mean_absolute_error(y_validation, predictions_validation))"]}],"metadata":{"colab":{"provenance":[{"file_id":"1kHkaqxz9sVdaOC2i4FJVOOFW9cCiBkYu","timestamp":1635795339650}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}
