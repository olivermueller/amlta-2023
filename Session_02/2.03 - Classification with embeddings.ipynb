{"cells":[{"cell_type":"markdown","metadata":{"id":"LJrKCbjZsqpo"},"source":["# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"]},{"cell_type":"markdown","metadata":{"id":"V-DU0hkyVyPi"},"source":["# <font color=\"#003660\">Week 2: Unsupervised NLP</font>"]},{"cell_type":"markdown","metadata":{"id":"mhy42GjRV3ON"},"source":["# <font color=\"#003660\">Notebook 3: Classification with Word Embeddings</font>\n","\n","<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n","\n","<p>\n","<center>\n","<div>\n","    <font color=\"#085986\"><b>By the end of this lesson, you will be able to...</b><br><br>\n","        ... train a classifier with mean word embeddings as features.\n","    </font>\n","</div>\n","</center>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"C6vVpwIFsqps"},"source":["# Import packages\n","\n","As always, we first need to load a number of required Python packages:\n","- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n","- `numpy` is a library adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n","- `SQLAlchemy`, together with `pymysql`, allows to communicate with SQL databases.\n","- `getpass` provides function to safely enter passwords.\n","- `spacy` offers industrial-strength natural language processing.\n","- `en_core_web_md` is a pre-trained Spacy model that has word embeddings included\n","- `sklearn` is the de-facto standard machine learning package in Python."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2870,"status":"ok","timestamp":1667487240135,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-60},"id":"5NpTS4Z2Vvzy","outputId":"f4845ece-3800-4186-97cc-8248dc38db27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pymysql\n","  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n","\u001b[?25hInstalling collected packages: pymysql\n","Successfully installed pymysql-1.0.2\n"]}],"source":["# Install packages\n","!pip install pymysql"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMrhkr83sqpt"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sqlalchemy import create_engine\n","import getpass\n","import spacy\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn import metrics\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"markdown","metadata":{"id":"jZd82t53sqpu"},"source":["# Load documents"]},{"cell_type":"markdown","metadata":{"id":"IsrCafxksqpv"},"source":["We load our data from a MySQL database. For security reasons, we don't store the database credentials here; please have a look at Panda to get them."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28801,"status":"ok","timestamp":1667487310322,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-60},"id":"vSIGfKcXsqpv","outputId":"49657478-09c8-498a-a4df-7ad0a70f4af6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Username: student\n","Password: ··········\n","Server: manila.uni-paderborn.de\n","Database: aml4ta\n"]}],"source":["# Get credentials\n","user = input(\"Username: \")\n","passwd = getpass.getpass(\"Password: \")\n","server = input(\"Server: \")\n","db = input(\"Database: \")\n","\n","# Create an engine instance (SQLAlchemy)\n","engine = create_engine(\"mysql+pymysql://{}:{}@{}/{}\".format(user, passwd ,server, db))\n","\n","# Define SQL query\n","sql_query = \"SELECT * FROM WineDataset\"\n","\n","# Query dataset (pandas)\n","corpus = pd.read_sql(sql=sql_query, con=engine)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667487310322,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-60},"id":"7NsIQrLiSEak","outputId":"e0c1e2bb-0ce8-409a-c1c8-10181de4107c"},"outputs":[{"data":{"text/plain":["(129971, 16)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["corpus.shape"]},{"cell_type":"markdown","metadata":{"id":"1v8oiPAcsqpx"},"source":["# Preprocess documents"]},{"cell_type":"markdown","metadata":{"id":"7psnR5cmQLBx"},"source":["Split data into training, validation, and test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSObnTaWdgdM"},"outputs":[],"source":["training = corpus[corpus[\"testset\"] == 0]\n","validation = training.iloc[80000:100000,]\n","training = training.iloc[0:80000,]\n","test = corpus[corpus[\"testset\"] == 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667487310323,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-60},"id":"m05pjMr8Rvxs","outputId":"f920cd58-ed8d-4764-b702-685c68725172"},"outputs":[{"name":"stdout","output_type":"stream","text":["(80000, 16)\n","(20000, 16)\n","(29970, 16)\n"]}],"source":["print(training.shape)\n","print(validation.shape)\n","print(test.shape)"]},{"cell_type":"markdown","metadata":{"id":"clAMcveqPOjb"},"source":["# Vectorize documents"]},{"cell_type":"markdown","metadata":{"id":"bSrHVdoZsqpy"},"source":["Instead of using a BoW model, we will vectorize the documents by computing the average word embeddings over all words of a document. For this, we will use the word embeddings we have trained on the wine dataset."]},{"cell_type":"markdown","metadata":{"id":"Y9L1oJXkSflG"},"source":["Convert the trained word embeddings to a format that Spacy understands (read more: https://spacy.io/api/cli#init-vectors)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19050,"status":"ok","timestamp":1667487339464,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-60},"id":"pblMcujrVt7-","outputId":"e6ecdc71-aec0-4dca-cd81-653b47f6bb08"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Set up Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vlutz00FHpln"},"outputs":[],"source":["!python -m spacy init vectors en /content/drive/MyDrive/colab_notebooks/AML4TA2022/Session_03/data/wine_300dim_10minwords_4context /content/drive/MyDrive/colab_notebooks/AML4TA2022/Session_03/data"]},{"cell_type":"markdown","metadata":{"id":"AWPHcopnSlT8"},"source":["Load the custom embeddings and extract the mean word embeddings for each document."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sh4KVmP6sqpy"},"outputs":[],"source":["nlp = spacy.load(\"/content/drive/MyDrive/colab_notebooks/AML4TA2022/Session_03/data\")\n","\n","def spacy_prep(dataset):\n","  vectors = []\n","  dataset = dataset.to_dict(\"records\")\n","  for i, entry in enumerate(dataset):\n","      text = nlp(entry[u'description'])\n","      vectors.append(text.vector)\n","  return(np.array(vectors))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4rKCZRs9tlj"},"outputs":[],"source":["X_training = spacy_prep(training)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1667487669909,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-60},"id":"UyLoiearsqpz","outputId":"6cbccbc0-6d8d-4f6e-c391-a0a49d40828e"},"outputs":[{"data":{"text/plain":["(80000, 300)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["X_training.shape"]},{"cell_type":"markdown","metadata":{"id":"7QTlJ4BDsqp3"},"source":["Store the labels that we want to predict in a separate variable."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499,"status":"ok","timestamp":1667487691923,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-60},"id":"gUpaU5Pgsqp3","outputId":"f6c3a58d-f0a1-4804-a251-bd3b486c303e"},"outputs":[{"data":{"text/plain":["count    80000.000000\n","mean         0.095137\n","std          0.293407\n","min          0.000000\n","25%          0.000000\n","50%          0.000000\n","75%          0.000000\n","max          1.000000\n","Name: verygood, dtype: float64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["y_training = training[\"verygood\"]\n","y_training.describe()"]},{"cell_type":"markdown","metadata":{"id":"biwWaNjNsqp4"},"source":["# Train classifier on training set"]},{"cell_type":"markdown","metadata":{"id":"WTHaUsAosqp4"},"source":["Fit a classifier with word embeddings as the features and wine quality (i.e., `verygood` variable) as the label."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZkAh7oesqp4"},"outputs":[],"source":["clf = LogisticRegression(max_iter=1000).fit(X_training, y_training)"]},{"cell_type":"markdown","metadata":{"id":"663LU5XQsqp5"},"source":["# Evaluate accuracy on validation set"]},{"cell_type":"markdown","metadata":{"id":"K8-z8rqVsqp6"},"source":["Before trying to predict the labels for the official test set (on Kaggle), we evaluate the predictive accurcay of our model on the validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCZDzJOR51SZ"},"outputs":[],"source":["X_validation = spacy_prep(validation)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiUIhoK0sqp6"},"outputs":[],"source":["y_validation = validation[\"verygood\"]"]},{"cell_type":"markdown","metadata":{"id":"4upAshmAsqp6"},"source":["Call the predict function of our model with the validation data and calculate precision, recall and F1-score."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1667487717429,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-60},"id":"3Ngkprkgsqp6","outputId":"602be238-ac09-4d59-fd24-f5ce26896f89"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.92      0.99      0.95     18001\n","           1       0.59      0.18      0.28      1999\n","\n","    accuracy                           0.91     20000\n","   macro avg       0.75      0.59      0.62     20000\n","weighted avg       0.88      0.91      0.88     20000\n","\n"]}],"source":["predictions_validation = clf.predict(X_validation)\n","print(metrics.classification_report(y_validation, predictions_validation))"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1kHkaqxz9sVdaOC2i4FJVOOFW9cCiBkYu","timestamp":1636383829898}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}
